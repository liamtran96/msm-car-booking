# PostgreSQL - Client Apps (Part 14)

## 


**URL:** https://www.postgresql.org/docs/18/app-pgverifybackup.html

**Contents:**
- pg_verifybackup
- Synopsis
- Description
- Options
- Examples
- See Also

pg_verifybackup — verify the integrity of a base backup of a PostgreSQL cluster

pg_verifybackup [option...]

pg_verifybackup is used to check the integrity of a database cluster backup taken using pg_basebackup against a backup_manifest generated by the server at the time of the backup. The backup may be stored either in the "plain" or the "tar" format; this includes tar-format backups compressed with any algorithm supported by pg_basebackup. However, at present, WAL verification is supported only for plain-format backups. Therefore, if the backup is stored in tar-format, the -n, --no-parse-wal option should be used.

It is important to note that the validation which is performed by pg_verifybackup does not and cannot include every check which will be performed by a running server when attempting to make use of the backup. Even if you use this tool, you should still perform test restores and verify that the resulting databases work as expected and that they appear to contain the correct data. However, pg_verifybackup can detect many problems that commonly occur due to storage problems or user error.

Backup verification proceeds in four stages. First, pg_verifybackup reads the backup_manifest file. If that file does not exist, cannot be read, is malformed, fails to match the system identifier with pg_control of the backup directory or fails verification against its own internal checksum, pg_verifybackup will terminate with a fatal error.

Second, pg_verifybackup will attempt to verify that the data files currently stored on disk are exactly the same as the data files which the server intended to send, with some exceptions that are described below. Extra and missing files will be detected, with a few exceptions. This step will ignore the presence or absence of, or any modifications to, postgresql.auto.conf, standby.signal, and recovery.signal, because it is expected that these files may have been created or modified as part of the process of taking the backup. It also won't complain about a backup_manifest file in the target directory or about anything inside pg_wal, even though these files won't be listed in the backup manifest. Only files are checked; the presence or absence of directories is not verified, except indirectly: if a directory is missing, any files it should have contained will necessarily also be missing.

Next, pg_verifybackup will checksum all the files, compare the checksums against the values in the manifest, and emit errors for any files for which the computed checksum does not match the checksum stored in the manifest. This step is not performed for any files which produced errors in the previous step, since they are already known to have problems. Files which were ignored in the previous step are also ignored in this step.

Finally, pg_verifybackup will use the manifest to verify that the write-ahead log records which will be needed to recover the backup are present and that they can be read and parsed. The backup_manifest contains information about which write-ahead log records will be needed, and pg_verifybackup will use that information to invoke pg_waldump to parse those write-ahead log records. The --quiet flag will be used, so that pg_waldump will only report errors, without producing any other output. While this level of verification is sufficient to detect obvious problems such as a missing file or one whose internal checksums do not match, they aren't extensive enough to detect every possible problem that might occur when attempting to recover. For instance, a server bug that produces write-ahead log records that have the correct checksums but specify nonsensical actions can't be detected by this method.

Note that if extra WAL files which are not required to recover the backup are present, they will not be checked by this tool, although a separate invocation of pg_waldump could be used for that purpose. Also note that WAL verification is version-specific: you must use the version of pg_verifybackup, and thus of pg_waldump, which pertains to the backup being checked. In contrast, the data file integrity checks should work with any version of the server that generates a backup_manifest file.

pg_verifybackup accepts the following command-line arguments:

Exit as soon as a problem with the backup is detected. If this option is not specified, pg_verifybackup will continue checking the backup even after a problem has been detected, and will report all problems detected as errors.

Specifies the format of the backup. format can be one of the following:

Backup consists of plain files with the same layout as the source server's data directory and tablespaces.

Backup consists of tar files, which may be compressed. A valid backup includes the main data directory in a file named base.tar, the WAL files in pg_wal.tar, and separate tar files for each tablespace, named after the tablespace's OID. If the backup is compressed, the relevant compression extension is added to the end of each file name.

Ignore the specified file or directory, which should be expressed as a relative path name, when comparing the list of data files actually present in the backup to those listed in the backup_manifest file. If a directory is specified, this option affects the entire subtree rooted at that location. Complaints about extra files, missing files, file size differences, or checksum mismatches will be suppressed if the relative path name matches the specified path name. This option can be specified multiple times.

Use the manifest file at the specified path, rather than one located in the root of the backup directory.

Don't attempt to parse write-ahead log data that will be needed to recover from this backup.

Enable progress reporting. Turning this on will deliver a progress report while verifying checksums.

This option cannot be used together with the option --quiet.

Don't print anything when a backup is successfully verified.

Do not verify data file checksums. The presence or absence of files and the sizes of those files will still be checked. This is much faster, because the files themselves do not need to be read.

Try to parse WAL files stored in the specified directory, rather than in pg_wal. This may be useful if the backup is stored in a separate location from the WAL archive.

Other options are also available:

Print the pg_verifybackup version and exit.

Show help about pg_verifybackup command line arguments, and exit.

To create a base backup of the server at mydbserver and verify the integrity of the backup:

To create a base backup of the server at mydbserver, move the manifest somewhere outside the backup directory, and verify the backup:

To verify a backup while ignoring a file that was added manually to the backup directory, and also skipping checksum verification:

**Examples:**

Example 1 (unknown):
```unknown
pg_verifybackup
```

Example 2 (unknown):
```unknown
pg_basebackup
```

Example 3 (unknown):
```unknown
backup_manifest
```

Example 4 (unknown):
```unknown
-n, --no-parse-wal
```

---


---

## 


**URL:** https://www.postgresql.org/docs/18/app-vacuumdb.html

**Contents:**
- vacuumdb
- Synopsis
- Description
- Options
  - Tip
- Environment
- Diagnostics
- Examples
- See Also

vacuumdb — garbage-collect and analyze a PostgreSQL database

vacuumdb [connection-option...] [option...] [ -t | --table table [( column [,...] )] ] ... [ dbname | -a | --all ]

vacuumdb [connection-option...] [option...] [ -n | --schema schema ] ... [ dbname | -a | --all ]

vacuumdb [connection-option...] [option...] [ -N | --exclude-schema schema ] ... [ dbname | -a | --all ]

vacuumdb is a utility for cleaning a PostgreSQL database. vacuumdb will also generate internal statistics used by the PostgreSQL query optimizer.

vacuumdb is a wrapper around the SQL command VACUUM. There is no effective difference between vacuuming and analyzing databases via this utility and via other methods for accessing the server.

vacuumdb accepts the following command-line arguments:

Vacuum all databases.

Specifies the Buffer Access Strategy ring buffer size for a given invocation of vacuumdb. This size is used to calculate the number of shared buffers which will be reused as part of this strategy. See VACUUM.

Specifies the name of the database to be cleaned or analyzed, when -a/--all is not used. If this is not specified, the database name is read from the environment variable PGDATABASE. If that is not set, the user name specified for the connection is used. The dbname can be a connection string. If so, connection string parameters will override any conflicting command line options.

Disable skipping pages based on the contents of the visibility map.

Echo the commands that vacuumdb generates and sends to the server.

Perform “full” vacuuming.

Aggressively “freeze” tuples.

Always remove index entries pointing to dead tuples.

Execute the vacuum or analyze commands in parallel by running njobs commands simultaneously. This option may reduce the processing time but it also increases the load on the database server.

vacuumdb will open njobs connections to the database, so make sure your max_connections setting is high enough to accommodate all connections.

Note that using this mode together with the -f (FULL) option might cause deadlock failures if certain system catalogs are processed in parallel.

Only execute the vacuum or analyze commands on tables with a multixact ID age of at least mxid_age. This setting is useful for prioritizing tables to process to prevent multixact ID wraparound (see Section 24.1.5.1).

For the purposes of this option, the multixact ID age of a relation is the greatest of the ages of the main relation and its associated TOAST table, if one exists. Since the commands issued by vacuumdb will also process the TOAST table for the relation if necessary, it does not need to be considered separately.

Only execute the vacuum or analyze commands on tables with a transaction ID age of at least xid_age. This setting is useful for prioritizing tables to process to prevent transaction ID wraparound (see Section 24.1.5).

For the purposes of this option, the transaction ID age of a relation is the greatest of the ages of the main relation and its associated TOAST table, if one exists. Since the commands issued by vacuumdb will also process the TOAST table for the relation if necessary, it does not need to be considered separately.

Only analyze relations that are missing statistics for a column, index expression, or extended statistics object. When used with --analyze-in-stages, this option prevents vacuumdb from temporarily replacing existing statistics with ones generated with lower statistics targets, thus avoiding transiently worse query optimizer choices.

This option can only be used in conjunction with --analyze-only or --analyze-in-stages.

Note that --missing-stats-only requires SELECT privileges on pg_statistic and pg_statistic_ext_data, which are restricted to superusers by default.

Clean or analyze all tables in schema only. Multiple schemas can be vacuumed by writing multiple -n switches.

Do not clean or analyze any tables in schema. Multiple schemas can be excluded by writing multiple -N switches.

Do not remove index entries pointing to dead tuples.

Skip the main relation.

Skip the TOAST table associated with the table to vacuum, if any.

Do not truncate empty pages at the end of the table.

Specify the number of parallel workers for parallel vacuum. This allows the vacuum to leverage multiple CPUs to process indexes. See VACUUM.

Do not display progress messages.

Skip relations that cannot be immediately locked for processing.

Clean or analyze table only. Column names can be specified only in conjunction with the --analyze or --analyze-only options. Multiple tables can be vacuumed by writing multiple -t switches.

If you specify columns, you probably have to escape the parentheses from the shell. (See examples below.)

Print detailed information during processing.

Print the vacuumdb version and exit.

Also calculate statistics for use by the optimizer.

Only calculate statistics for use by the optimizer (no vacuum).

Only calculate statistics for use by the optimizer (no vacuum), like --analyze-only. Run three stages of analyze; the first stage uses the lowest possible statistics target (see default_statistics_target) to produce usable statistics faster, and subsequent stages build the full statistics.

This option is only useful to analyze a database that currently has no statistics or has wholly incorrect ones, such as if it is newly populated from a restored dump or by pg_upgrade. Be aware that running with this option in a database with existing statistics may cause the query optimizer choices to become transiently worse due to the low statistics targets of the early stages.

Show help about vacuumdb command line arguments, and exit.

vacuumdb also accepts the following command-line arguments for connection parameters:

Specifies the host name of the machine on which the server is running. If the value begins with a slash, it is used as the directory for the Unix domain socket.

Specifies the TCP port or local Unix domain socket file extension on which the server is listening for connections.

User name to connect as.

Never issue a password prompt. If the server requires password authentication and a password is not available by other means such as a .pgpass file, the connection attempt will fail. This option can be useful in batch jobs and scripts where no user is present to enter a password.

Force vacuumdb to prompt for a password before connecting to a database.

This option is never essential, since vacuumdb will automatically prompt for a password if the server demands password authentication. However, vacuumdb will waste a connection attempt finding out that the server wants a password. In some cases it is worth typing -W to avoid the extra connection attempt.

When the -a/--all is used, connect to this database to gather the list of databases to vacuum. If not specified, the postgres database will be used, or if that does not exist, template1 will be used. This can be a connection string. If so, connection string parameters will override any conflicting command line options. Also, connection string parameters other than the database name itself will be re-used when connecting to other databases.

Default connection parameters

Specifies whether to use color in diagnostic messages. Possible values are always, auto and never.

This utility, like most other PostgreSQL utilities, also uses the environment variables supported by libpq (see Section 32.15).

In case of difficulty, see VACUUM and psql for discussions of potential problems and error messages. The database server must be running at the targeted host. Also, any default connection settings and environment variables used by the libpq front-end library will apply.

To clean the database test:

To clean and analyze for the optimizer a database named bigdb:

To clean a single table foo in a database named xyzzy, and analyze a single column bar of the table for the optimizer:

To clean all tables in the foo and bar schemas in a database named xyzzy:

**Examples:**

Example 1 (unknown):
```unknown
connection-option
```

Example 2 (unknown):
```unknown
connection-option
```

Example 3 (unknown):
```unknown
connection-option
```

Example 4 (unknown):
```unknown
--exclude-schema
```

---


---

